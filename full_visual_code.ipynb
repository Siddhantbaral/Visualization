{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 📊 Climate Visualization Pipeline for Nepal  \n",
        "**Author:** @Siddhant Baral  \n",
        "**Dataset:** EC-Earth3-Veg (CMIP6, ScenarioMIP)  \n",
        "\n",
        "This notebook automates the visualization of annual climate variables from EC-Earth3-Veg GCM outputs for Nepal. It processes `.nc` files across two scenarios (`ssp245`, `ssp585`) and three variables (`tasmin`, `tasmax`, `pr`), generating:\n",
        "\n",
        "- 🗺️ Animated spatial maps of annual means/sums  \n",
        "- 📈 Trend plots with rolling averages and extremes  \n",
        "- 🎞️ Combined GIFs for each variable-scenario pair  \n",
        "- ⚡ Parallel execution with runtime logging and performance tracking  \n",
        "\n",
        "All outputs are saved to `/content/drive/MyDrive/climate_outputs`.\n",
        "\n",
        "---\n",
        "\n",
        "### 📄 License & Attribution\n",
        "\n",
        "This work uses downscaled results from the **Rhodium Group / Climate Impact Lab Global Downscaled Projections for Climate Impacts Research (R/CIL GDPCIR)** dataset. These results are licensed under the [Creative Commons Attribution 4.0 International License](http://creativecommons.org/licenses/by/4.0/). Please note:\n",
        "\n",
        "- This license applies **only to the downscaled results**.\n",
        "- The original GCM output from EC-Earth3-Veg may have **different license terms**.\n",
        "- Proper attribution is required for both the **original model** and the **R/CIL GDPCIR dataset**.\n",
        "\n",
        "For full license details, see:\n",
        "- [EC-Earth3-Veg license text](https://raw.githubusercontent.com/ClimateImpactLab/downscaleCMIP6/master/data_licenses/EC-Earth3-Veg.txt)  \n",
        "- [R/CIL GDPCIR README and citation info](https://github.com/ClimateImpactLab/downscaleCMIP6/blob/master/README.rst)  \n",
        "- [Code license for downscaling tools](https://github.com/ClimateImpactLab/downscaleCMIP6/blob/master/LICENSE)\n",
        "\n",
        "---\n",
        "\n",
        "### 📚 Citations\n",
        "\n",
        "**CMIP6 Citation:**  \n",
        "EC-Earth Consortium (EC-Earth) (2019). *EC-Earth3-Veg model output prepared for CMIP6 CMIP*. Version 20200225. Earth System Grid Federation. [https://doi.org/10.22033/ESGF/CMIP6.642](https://doi.org/10.22033/ESGF/CMIP6.642)\n",
        "\n",
        "**ScenarioMIP Citation:**  \n",
        "EC-Earth Consortium (EC-Earth) (2019). *EC-Earth3-Veg model output prepared for CMIP6 ScenarioMIP*. Version 20200225. Earth System Grid Federation. [https://doi.org/10.22033/ESGF/CMIP6.727](https://doi.org/10.22033/ESGF/CMIP6.727)"
      ],
      "metadata": {
        "id": "Asq_vi7Jmybd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For Nepal\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "\n",
        "def visualize_climate_variable(file_path, var_name, scenario, label, cmap, unit, is_sum=False, shape=None, save_dir=\"/content/drive/MyDrive/climate_outputs\"):\n",
        "    import xarray as xr, geopandas as gpd, matplotlib.pyplot as plt\n",
        "    from matplotlib.animation import FuncAnimation\n",
        "    from matplotlib.colors import Normalize\n",
        "    from matplotlib.collections import PolyCollection\n",
        "    import numpy as np, pandas as pd\n",
        "    from PIL import Image\n",
        "\n",
        "    ds = xr.open_dataset(file_path)\n",
        "    ds[\"time\"] = pd.to_datetime(ds[\"time\"].values)\n",
        "    ds = ds.set_coords(\"time\")\n",
        "\n",
        "    annual = ds[var_name].groupby(\"time.year\")\n",
        "    annual_data = annual.sum(dim=\"time\") if is_sum else annual.mean(dim=\"time\")\n",
        "    years = annual_data.year.values\n",
        "    mean_values = annual_data.mean(dim=[\"lat\", \"lon\"]).values\n",
        "    rolling = xr.DataArray(mean_values, dims=\"year\", coords={\"year\": years}).rolling(year=10, center=True).mean()\n",
        "    max_idx, min_idx = np.nanargmax(mean_values), np.nanargmin(mean_values)\n",
        "\n",
        "    # === Map Animation ===\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    data0 = annual_data.isel(year=0)\n",
        "    im = ax.imshow(data0.values,\n",
        "                   extent=[data0.lon.min(), data0.lon.max(), data0.lat.min(), data0.lat.max()],\n",
        "                   origin='lower', cmap=cmap,\n",
        "                   vmin=float(np.nanmin(annual_data)), vmax=float(np.nanmax(annual_data)), aspect='auto')\n",
        "    shape.boundary.plot(ax=ax, edgecolor=\"black\", linewidth=1.2, zorder=5)\n",
        "    cbar = plt.colorbar(im, ax=ax, orientation=\"vertical\", fraction=0.035, pad=0.02, shrink=0.8)\n",
        "    cbar.set_label(f\"{label} ({unit})\", fontsize=9)\n",
        "    ax.set_xlim(*shape.total_bounds[[0, 2]] + np.array([-0.2, 0.2]))\n",
        "    ax.set_ylim(*shape.total_bounds[[1, 3]] + np.array([-0.2, 0.2]))\n",
        "    ax.set_xlabel(\"Longitude\")\n",
        "    ax.set_ylabel(\"Latitude\")\n",
        "    title_text = ax.set_title(\"\")\n",
        "\n",
        "    def update_map(frame):\n",
        "        im.set_data(annual_data.isel(year=frame).values)\n",
        "        title_text.set_text(f\"Nepal {label} {scenario} - Year {int(years[frame])}\")\n",
        "        return [im, title_text]\n",
        "\n",
        "    map_gif = f\"{save_dir}/{var_name}_{scenario}_map.gif\"\n",
        "    map_anim = FuncAnimation(fig, update_map, frames=len(years), interval=300)\n",
        "    map_anim.save(map_gif, writer=\"pillow\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    # === Trend Animation ===\n",
        "    fig, ax = plt.subplots(figsize=(7, 4))\n",
        "    cmap_trend = plt.cm.viridis\n",
        "    norm = Normalize(vmin=years.min(), vmax=years.max())\n",
        "\n",
        "    def update_trend(frame):\n",
        "        ax.clear()\n",
        "        for i in range(frame):\n",
        "            ax.plot(years[i:i+2], mean_values[i:i+2], color=cmap_trend(norm(years[i])), linewidth=2.5)\n",
        "            verts = [(years[i], 0), (years[i], mean_values[i]), (years[i+1], mean_values[i+1]), (years[i+1], 0)]\n",
        "            ax.add_collection(PolyCollection([verts], facecolors=[cmap_trend(norm(years[i]))], alpha=0.35))\n",
        "        ax.plot(years, rolling, color=\"black\", linestyle=\"--\", linewidth=2.5, label=\"10-yr trend\")\n",
        "        ax.scatter(years[max_idx], mean_values[max_idx], color=\"blue\", marker=\"^\", s=120, label=\"Max Year\")\n",
        "        ax.scatter(years[min_idx], mean_values[min_idx], color=\"red\", marker=\"v\", s=120, label=\"Min Year\")\n",
        "        if frame >= max_idx:\n",
        "            ax.text(years[max_idx], mean_values[max_idx]*1.05, f\"{years[max_idx]}\", color=\"blue\", fontsize=9,\n",
        "                    ha=\"center\", va=\"bottom\", fontweight=\"bold\")\n",
        "        if frame >= min_idx:\n",
        "            ax.text(years[min_idx], mean_values[min_idx]*0.95, f\"{years[min_idx]}\", color=\"red\", fontsize=9,\n",
        "                    ha=\"center\", va=\"top\", fontweight=\"bold\")\n",
        "        ax.set_xlim(years[0], years[-1])\n",
        "        ax.set_ylim(np.nanmin(mean_values)*0.95, np.nanmax(mean_values)*1.15)\n",
        "        ax.set_title(f\"{label} in Nepal {scenario} ({unit})\", fontsize=12, fontweight=\"bold\")\n",
        "        ax.set_xlabel(\"Year\")\n",
        "        ax.set_ylabel(unit)\n",
        "        ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "        ax.legend(loc=\"upper left\", fontsize=9, frameon=True, facecolor=\"white\", framealpha=0.8)\n",
        "        fig.subplots_adjust(bottom=0.15, top=0.9)\n",
        "\n",
        "    trend_gif = f\"{save_dir}/{var_name}_{scenario}_trend.gif\"\n",
        "    trend_anim = FuncAnimation(fig, update_trend, frames=len(years), interval=300)\n",
        "    trend_anim.save(trend_gif, writer=\"pillow\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    # === Combine GIFs ===\n",
        "    map_frames = Image.open(map_gif)\n",
        "    trend_frames = Image.open(trend_gif)\n",
        "    frames = []\n",
        "    for i in range(map_frames.n_frames):\n",
        "        map_frames.seek(i)\n",
        "        trend_frames.seek(i)\n",
        "        map_img = map_frames.convert(\"RGBA\")\n",
        "        trend_img = trend_frames.convert(\"RGBA\").resize((map_img.width, trend_frames.height))\n",
        "        new_frame = Image.new(\"RGBA\", (map_img.width, map_img.height + trend_img.height), (255, 255, 255, 255))\n",
        "        new_frame.paste(map_img, (0, 0))\n",
        "        new_frame.paste(trend_img, (0, map_img.height))\n",
        "        frames.append(new_frame)\n",
        "\n",
        "    combined_gif = f\"{save_dir}/{var_name}_{scenario}_combined.gif\"\n",
        "    frames[0].save(combined_gif, save_all=True, append_images=frames[1:], loop=0, duration=300)\n",
        "    print(\"✅ Saved:\", combined_gif)\n",
        "\n",
        "\n",
        "# Load Nepal shapefile once\n",
        "import geopandas as gpd\n",
        "nepal_shape = gpd.read_file(\"/content/drive/MyDrive/climate_data/Nepal_shp/dissolved.shp\").to_crs(\"EPSG:4326\")\n",
        "\n",
        "# Define scenarios and variable configs\n",
        "scenarios = [\"ssp245\", \"ssp585\"]\n",
        "variables = {\n",
        "    \"tasmin\": {\"label\": \"Annual Min Temperature\", \"cmap\": \"coolwarm\", \"unit\": \"K\", \"is_sum\": False},\n",
        "    \"tasmax\": {\"label\": \"Annual Max Temperature\", \"cmap\": \"coolwarm\", \"unit\": \"K\", \"is_sum\": False},\n",
        "    \"pr\":     {\"label\": \"Annual Precipitation\",    \"cmap\": \"YlGnBu\",   \"unit\": \"mm/year\", \"is_sum\": True}\n",
        "}\n",
        "\n",
        "# Prepare task arguments\n",
        "task_args = []\n",
        "for scenario in scenarios:\n",
        "    for var, props in variables.items():\n",
        "        file_path = f\"/content/drive/MyDrive/EC-Earth3-Veg/{scenario}/{var}_E3Veg_{scenario}_nepal_2015_2100_reparsed.nc\"\n",
        "        task_args.append((file_path, var, scenario, props, nepal_shape))\n",
        "\n",
        "# Wrapper with logging\n",
        "def run_visualization(args):\n",
        "    file_path, var_name, scenario, props, shape = args\n",
        "    start = time.time()\n",
        "    print(f\"▶️ Starting: {var_name} | {scenario}\")\n",
        "    visualize_climate_variable(\n",
        "        file_path=file_path,\n",
        "        var_name=var_name,\n",
        "        scenario=scenario,\n",
        "        label=props[\"label\"],\n",
        "        cmap=props[\"cmap\"],\n",
        "        unit=props[\"unit\"],\n",
        "        is_sum=props[\"is_sum\"],\n",
        "        shape=shape\n",
        "    )\n",
        "    end = time.time()\n",
        "    duration = timedelta(seconds=end - start)\n",
        "    print(f\"✅ Done: {var_name} | {scenario} in {duration}\")\n",
        "    return (var_name, scenario, duration)\n",
        "\n",
        "# Run in parallel with progress tracking\n",
        "start_all = time.time()\n",
        "results = []\n",
        "with ProcessPoolExecutor(max_workers=3) as executor:\n",
        "    futures = {executor.submit(run_visualization, args): args for args in task_args}\n",
        "    total = len(futures)\n",
        "    completed = 0\n",
        "    for future in as_completed(futures):\n",
        "        result = future.result()\n",
        "        results.append(result)\n",
        "        completed += 1\n",
        "        elapsed = time.time() - start_all\n",
        "        avg_time = elapsed / completed\n",
        "        remaining = avg_time * (total - completed)\n",
        "        print(f\"⏳ {completed}/{total} done | Est. time left: {timedelta(seconds=remaining)}\")\n",
        "# Summary\n",
        "print(\"\\n📋 Task Summary:\")\n",
        "for var, scenario, duration in results:\n",
        "    print(f\"• {var} | {scenario} → {duration}\")\n",
        "print(f\"\\n🏁 Total time: {timedelta(seconds=time.time() - start_all)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjzmmrrkkiSA",
        "outputId": "09642e84-a582-48d9-94b3-2af2eee20340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ Starting: tasmin | ssp245\n",
            "▶️ Starting: tasmax | ssp245\n",
            "▶️ Starting: pr | ssp245\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/tasmin_ssp245_combined.gif\n",
            "✅ Done: tasmin | ssp245 in 0:02:26.306591\n",
            "▶️ Starting: tasmin | ssp585\n",
            "⏳ 1/6 done | Est. time left: 0:12:11.861461\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/pr_ssp245_combined.gif\n",
            "✅ Done: pr | ssp245 in 0:02:27.338528\n",
            "▶️ Starting: tasmax | ssp585\n",
            "⏳ 2/6 done | Est. time left: 0:04:54.994733\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/tasmax_ssp245_combined.gif\n",
            "✅ Done: tasmax | ssp245 in 0:02:29.126221\n",
            "▶️ Starting: pr | ssp585\n",
            "⏳ 3/6 done | Est. time left: 0:02:29.198211\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/tasmin_ssp585_combined.gif\n",
            "✅ Done: tasmin | ssp585 in 0:02:17.036085\n",
            "⏳ 4/6 done | Est. time left: 0:02:21.719863\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/tasmax_ssp585_combined.gif\n",
            "✅ Done: tasmax | ssp585 in 0:02:20.320236\n",
            "⏳ 5/6 done | Est. time left: 0:00:57.563320\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/pr_ssp585_combined.gif\n",
            "✅ Done: pr | ssp585 in 0:02:20.069719\n",
            "⏳ 6/6 done | Est. time left: 0:00:00\n",
            "\n",
            "📋 Task Summary:\n",
            "• tasmin | ssp245 → 0:02:26.306591\n",
            "• pr | ssp245 → 0:02:27.338528\n",
            "• tasmax | ssp245 → 0:02:29.126221\n",
            "• tasmin | ssp585 → 0:02:17.036085\n",
            "• tasmax | ssp585 → 0:02:20.320236\n",
            "• pr | ssp585 → 0:02:20.069719\n",
            "\n",
            "🏁 Total time: 0:04:49.338402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For West Rapti River Basin\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "\n",
        "def visualize_climate_variable(file_path, var_name, scenario, label, cmap, unit, is_sum=False, shape=None, save_dir=\"/content/drive/MyDrive/climate_outputs/wrb_maps\"):\n",
        "    import xarray as xr, geopandas as gpd, matplotlib.pyplot as plt\n",
        "    from matplotlib.animation import FuncAnimation\n",
        "    from matplotlib.colors import Normalize\n",
        "    from matplotlib.collections import PolyCollection\n",
        "    import numpy as np, pandas as pd\n",
        "    from PIL import Image\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    ds = xr.open_dataset(file_path)\n",
        "    ds[\"time\"] = pd.to_datetime(ds[\"time\"].values)\n",
        "    ds = ds.set_coords(\"time\")\n",
        "\n",
        "    annual = ds[var_name].groupby(\"time.year\")\n",
        "    annual_data = annual.sum(dim=\"time\") if is_sum else annual.mean(dim=\"time\")\n",
        "    years = annual_data.year.values\n",
        "    mean_values = annual_data.mean(dim=[\"lat\", \"lon\"]).values\n",
        "    rolling = xr.DataArray(mean_values, dims=\"year\", coords={\"year\": years}).rolling(year=10, center=True).mean()\n",
        "    max_idx, min_idx = np.nanargmax(mean_values), np.nanargmin(mean_values)\n",
        "\n",
        "    # === Map Animation ===\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    data0 = annual_data.isel(year=0)\n",
        "    im = ax.imshow(data0.values,\n",
        "                   extent=[data0.lon.min(), data0.lon.max(), data0.lat.min(), data0.lat.max()],\n",
        "                   origin='lower', cmap=cmap,\n",
        "                   vmin=float(np.nanmin(annual_data)), vmax=float(np.nanmax(annual_data)), aspect='auto')\n",
        "    shape.boundary.plot(ax=ax, edgecolor=\"black\", linewidth=1.2, zorder=5)\n",
        "    cbar = plt.colorbar(im, ax=ax, orientation=\"vertical\", fraction=0.035, pad=0.02, shrink=0.8)\n",
        "    cbar.set_label(f\"{label} ({unit})\", fontsize=9)\n",
        "    ax.set_xlim(*shape.total_bounds[[0, 2]] + np.array([-0.2, 0.2]))\n",
        "    ax.set_ylim(*shape.total_bounds[[1, 3]] + np.array([-0.2, 0.2]))\n",
        "    ax.set_xlabel(\"Longitude\")\n",
        "    ax.set_ylabel(\"Latitude\")\n",
        "    title_text = ax.set_title(\"\")\n",
        "\n",
        "    def update_map(frame):\n",
        "        im.set_data(annual_data.isel(year=frame).values)\n",
        "        title_text.set_text(f\"WRB {label} {scenario} - Year {int(years[frame])}\")\n",
        "        return [im, title_text]\n",
        "\n",
        "    map_gif = f\"{save_dir}/{var_name}_{scenario}_map.gif\"\n",
        "    map_anim = FuncAnimation(fig, update_map, frames=len(years), interval=300)\n",
        "    map_anim.save(map_gif, writer=\"pillow\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    # === Trend Animation ===\n",
        "    fig, ax = plt.subplots(figsize=(7, 4))\n",
        "    cmap_trend = plt.cm.viridis\n",
        "    norm = Normalize(vmin=years.min(), vmax=years.max())\n",
        "\n",
        "    def update_trend(frame):\n",
        "        ax.clear()\n",
        "        for i in range(frame):\n",
        "            ax.plot(years[i:i+2], mean_values[i:i+2], color=cmap_trend(norm(years[i])), linewidth=2.5)\n",
        "            verts = [(years[i], 0), (years[i], mean_values[i]), (years[i+1], mean_values[i+1]), (years[i+1], 0)]\n",
        "            ax.add_collection(PolyCollection([verts], facecolors=[cmap_trend(norm(years[i]))], alpha=0.35))\n",
        "        ax.plot(years, rolling, color=\"black\", linestyle=\"--\", linewidth=2.5, label=\"10-yr trend\")\n",
        "        ax.scatter(years[max_idx], mean_values[max_idx], color=\"blue\", marker=\"^\", s=120, label=\"Max Year\")\n",
        "        ax.scatter(years[min_idx], mean_values[min_idx], color=\"red\", marker=\"v\", s=120, label=\"Min Year\")\n",
        "        if frame >= max_idx:\n",
        "            ax.text(years[max_idx], mean_values[max_idx]*1.05, f\"{years[max_idx]}\", color=\"blue\", fontsize=9,\n",
        "                    ha=\"center\", va=\"bottom\", fontweight=\"bold\")\n",
        "        if frame >= min_idx:\n",
        "            ax.text(years[min_idx], mean_values[min_idx]*0.95, f\"{years[min_idx]}\", color=\"red\", fontsize=9,\n",
        "                    ha=\"center\", va=\"top\", fontweight=\"bold\")\n",
        "        ax.set_xlim(years[0], years[-1])\n",
        "        ax.set_ylim(np.nanmin(mean_values)*0.95, np.nanmax(mean_values)*1.15)\n",
        "        ax.set_title(f\"{label} in WRB {scenario} ({unit})\", fontsize=12, fontweight=\"bold\")\n",
        "        ax.set_xlabel(\"Year\")\n",
        "        ax.set_ylabel(unit)\n",
        "        ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "        ax.legend(loc=\"upper left\", fontsize=9, frameon=True, facecolor=\"white\", framealpha=0.8)\n",
        "        fig.subplots_adjust(bottom=0.15, top=0.9)\n",
        "\n",
        "    trend_gif = f\"{save_dir}/{var_name}_{scenario}_trend.gif\"\n",
        "    trend_anim = FuncAnimation(fig, update_trend, frames=len(years), interval=300)\n",
        "    trend_anim.save(trend_gif, writer=\"pillow\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    # === Combine GIFs ===\n",
        "    map_frames = Image.open(map_gif)\n",
        "    trend_frames = Image.open(trend_gif)\n",
        "    frames = []\n",
        "    for i in range(map_frames.n_frames):\n",
        "        map_frames.seek(i)\n",
        "        trend_frames.seek(i)\n",
        "        map_img = map_frames.convert(\"RGBA\")\n",
        "        trend_img = trend_frames.convert(\"RGBA\").resize((map_img.width, trend_frames.height))\n",
        "        new_frame = Image.new(\"RGBA\", (map_img.width, map_img.height + trend_img.height), (255, 255, 255, 255))\n",
        "        new_frame.paste(map_img, (0, 0))\n",
        "        new_frame.paste(trend_img, (0, map_img.height))\n",
        "        frames.append(new_frame)\n",
        "\n",
        "    combined_gif = f\"{save_dir}/{var_name}_{scenario}_combined.gif\"\n",
        "    frames[0].save(combined_gif, save_all=True, append_images=frames[1:], loop=0, duration=300)\n",
        "    print(\"✅ Saved:\", combined_gif)\n",
        "\n",
        "\n",
        "# === Load WRB Shapefile ===\n",
        "import geopandas as gpd\n",
        "wrb_shape = gpd.read_file(\"/content/drive/MyDrive/WRB/watershed/watershed.shp\").to_crs(\"EPSG:4326\")\n",
        "\n",
        "# === Define Scenarios and Variables ===\n",
        "scenarios = [\"ssp245\", \"ssp585\"]\n",
        "variables = {\n",
        "    \"tasmin\": {\"label\": \"Annual Min Temperature\", \"cmap\": \"coolwarm\", \"unit\": \"K\", \"is_sum\": False},\n",
        "    \"tasmax\": {\"label\": \"Annual Max Temperature\", \"cmap\": \"coolwarm\", \"unit\": \"K\", \"is_sum\": False},\n",
        "    \"pr\":     {\"label\": \"Annual Precipitation\",    \"cmap\": \"YlGnBu\",   \"unit\": \"mm/year\", \"is_sum\": True}\n",
        "}\n",
        "\n",
        "# === Prepare Task Arguments ===\n",
        "task_args = []\n",
        "for scenario in scenarios:\n",
        "    for var, props in variables.items():\n",
        "        file_path = f\"/content/drive/MyDrive/WRB/gcm_data/{scenario}/wrb_{var}_{scenario}_fut.nc\"\n",
        "        task_args.append((file_path, var, scenario, props, wrb_shape))\n",
        "\n",
        "# === Run in Parallel ===\n",
        "def run_visualization(args):\n",
        "    file_path, var_name, scenario, props, shape = args\n",
        "    start = time.time()\n",
        "    print(f\"▶️ Starting: {var_name} | {scenario}\")\n",
        "    visualize_climate_variable(\n",
        "        file_path=file_path,\n",
        "        var_name=var_name,\n",
        "        scenario=scenario,\n",
        "        label=props[\"label\"],\n",
        "        cmap=props[\"cmap\"],\n",
        "        unit=props[\"unit\"],\n",
        "        is_sum=props[\"is_sum\"],\n",
        "        shape=shape\n",
        "    )\n",
        "    end = time.time()\n",
        "    duration = timedelta(seconds=end - start)\n",
        "    print(f\"✅ Done: {var_name} | {scenario} in {duration}\")\n",
        "    return (var_name, scenario, duration)\n",
        "\n",
        "start_all = time.time()\n",
        "results = []\n",
        "with ProcessPoolExecutor(max_workers=3) as executor:\n",
        "    futures = {executor.submit(run_visualization, args): args for args in task_args}\n",
        "    total = len(futures)\n",
        "    completed = 0\n",
        "    for future in as_completed(futures):\n",
        "        result = future.result()\n",
        "        results.append(result)\n",
        "        completed += 1\n",
        "        elapsed = time.time() - start_all\n",
        "        avg_time = elapsed / completed\n",
        "        remaining = avg_time * (total - completed)\n",
        "        print(f\"⏳ {completed}/{total} done | Est. time left: {timedelta(seconds=remaining)}\")\n",
        "# Summary\n",
        "print(\"\\n📋 Task Summary:\")\n",
        "for var, scenario, duration in results:\n",
        "    print(f\"• {var} | {scenario} → {duration}\")\n",
        "print(f\"\\n🏁 Total time: {timedelta(seconds=time.time() - start_all)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9m_7CuS2_fL",
        "outputId": "ae7acc8a-2a9b-4296-e0e4-fbd42bcd4d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ Starting: tasmax | ssp245▶️ Starting: pr | ssp245\n",
            "▶️ Starting: tasmin | ssp245\n",
            "\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/wrb_maps/tasmin_ssp245_combined.gif\n",
            "✅ Done: tasmin | ssp245 in 0:02:05.734621\n",
            "▶️ Starting: tasmin | ssp585\n",
            "⏳ 1/6 done | Est. time left: 0:10:28.949674\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/wrb_maps/pr_ssp245_combined.gif\n",
            "✅ Done: pr | ssp245 in 0:02:09.077653\n",
            "▶️ Starting: tasmax | ssp585\n",
            "⏳ 2/6 done | Est. time left: 0:04:18.286958\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/wrb_maps/tasmax_ssp245_combined.gif\n",
            "✅ Done: tasmax | ssp245 in 0:02:10.366982\n",
            "▶️ Starting: pr | ssp585\n",
            "⏳ 3/6 done | Est. time left: 0:02:10.422635\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/wrb_maps/tasmin_ssp585_combined.gif\n",
            "✅ Done: tasmin | ssp585 in 0:02:06.395281\n",
            "⏳ 4/6 done | Est. time left: 0:02:06.107218\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/wrb_maps/tasmax_ssp585_combined.gif\n",
            "✅ Done: tasmax | ssp585 in 0:02:06.622111\n",
            "⏳ 5/6 done | Est. time left: 0:00:51.155104\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/wrb_maps/pr_ssp585_combined.gif\n",
            "✅ Done: pr | ssp585 in 0:02:06.492954\n",
            "⏳ 6/6 done | Est. time left: 0:00:00\n",
            "\n",
            "📋 Task Summary:\n",
            "• tasmin | ssp245 → 0:02:05.734621\n",
            "• pr | ssp245 → 0:02:09.077653\n",
            "• tasmax | ssp245 → 0:02:10.366982\n",
            "• tasmin | ssp585 → 0:02:06.395281\n",
            "• tasmax | ssp585 → 0:02:06.622111\n",
            "• pr | ssp585 → 0:02:06.492954\n",
            "\n",
            "🏁 Total time: 0:04:16.976676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Even tighter WRB\n",
        "import os\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import geopandas as gpd\n",
        "\n",
        "# === Load WRB Shapefile (for boundary overlay only)\n",
        "wrb_shape = gpd.read_file(\"/content/drive/MyDrive/WRB/watershed/watershed.shp\").to_crs(\"EPSG:4326\")\n",
        "\n",
        "# === Visualization Function\n",
        "def visualize_climate_variable(file_path, var_name, scenario, label, cmap, unit, is_sum=False, shape=None, save_dir=\"/content/drive/MyDrive/climate_outputs/wrb_gifs/20kmbuffer\"):\n",
        "    import xarray as xr, matplotlib.pyplot as plt\n",
        "    from matplotlib.animation import FuncAnimation\n",
        "    from matplotlib.colors import Normalize\n",
        "    from matplotlib.collections import PolyCollection\n",
        "    import numpy as np, pandas as pd\n",
        "    from PIL import Image\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    ds = xr.open_dataset(file_path)\n",
        "    ds[\"time\"] = pd.to_datetime(ds[\"time\"].values)\n",
        "    ds = ds.set_coords(\"time\")\n",
        "\n",
        "    annual = ds[var_name].groupby(\"time.year\")\n",
        "    annual_data = annual.sum(dim=\"time\") if is_sum else annual.mean(dim=\"time\")\n",
        "    years = annual_data.year.values\n",
        "    mean_values = annual_data.mean(dim=[\"lat\", \"lon\"]).values\n",
        "    rolling = xr.DataArray(mean_values, dims=\"year\", coords={\"year\": years}).rolling(year=10, center=True).mean()\n",
        "    max_idx, min_idx = np.nanargmax(mean_values), np.nanargmin(mean_values)\n",
        "\n",
        "    # === Map Animation ===\n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    data0 = annual_data.isel(year=0)\n",
        "    im = ax.imshow(data0.values,\n",
        "                   extent=[data0.lon.min(), data0.lon.max(), data0.lat.min(), data0.lat.max()],\n",
        "                   origin='lower', cmap=cmap,\n",
        "                   vmin=float(np.nanmin(annual_data)), vmax=float(np.nanmax(annual_data)), aspect='auto')\n",
        "    shape.boundary.plot(ax=ax, edgecolor=\"black\", linewidth=1.2, zorder=5)\n",
        "    cbar = plt.colorbar(im, ax=ax, orientation=\"vertical\", fraction=0.035, pad=0.02, shrink=0.8)\n",
        "    cbar.set_label(f\"{label} ({unit})\", fontsize=9)\n",
        "    ax.set_xlim(*shape.total_bounds[[0, 2]] + np.array([-0.2, 0.2]))\n",
        "    ax.set_ylim(*shape.total_bounds[[1, 3]] + np.array([-0.2, 0.2]))\n",
        "    ax.set_xlabel(\"Longitude\")\n",
        "    ax.set_ylabel(\"Latitude\")\n",
        "    title_text = ax.set_title(\"\")\n",
        "\n",
        "    def update_map(frame):\n",
        "        im.set_data(annual_data.isel(year=frame).values)\n",
        "        title_text.set_text(f\"WRB {label} {scenario} - Year {int(years[frame])}\")\n",
        "        return [im, title_text]\n",
        "\n",
        "    map_gif = f\"{save_dir}/{var_name}_{scenario}_map.gif\"\n",
        "    map_anim = FuncAnimation(fig, update_map, frames=len(years), interval=300)\n",
        "    map_anim.save(map_gif, writer=\"pillow\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    # === Trend Animation ===\n",
        "    fig, ax = plt.subplots(figsize=(7, 4))\n",
        "    cmap_trend = plt.cm.viridis\n",
        "    norm = Normalize(vmin=years.min(), vmax=years.max())\n",
        "\n",
        "    def update_trend(frame):\n",
        "        ax.clear()\n",
        "        for i in range(frame):\n",
        "            ax.plot(years[i:i+2], mean_values[i:i+2], color=cmap_trend(norm(years[i])), linewidth=2.5)\n",
        "            verts = [(years[i], 0), (years[i], mean_values[i]), (years[i+1], mean_values[i+1]), (years[i+1], 0)]\n",
        "            ax.add_collection(PolyCollection([verts], facecolors=[cmap_trend(norm(years[i]))], alpha=0.35))\n",
        "        ax.plot(years, rolling, color=\"black\", linestyle=\"--\", linewidth=2.5, label=\"10-yr trend\")\n",
        "        ax.scatter(years[max_idx], mean_values[max_idx], color=\"blue\", marker=\"^\", s=120, label=\"Max Year\")\n",
        "        ax.scatter(years[min_idx], mean_values[min_idx], color=\"red\", marker=\"v\", s=120, label=\"Min Year\")\n",
        "        if frame >= max_idx:\n",
        "            ax.text(years[max_idx], mean_values[max_idx]*1.05, f\"{years[max_idx]}\", color=\"blue\", fontsize=9,\n",
        "                    ha=\"center\", va=\"bottom\", fontweight=\"bold\")\n",
        "        if frame >= min_idx:\n",
        "            ax.text(years[min_idx], mean_values[min_idx]*0.95, f\"{years[min_idx]}\", color=\"red\", fontsize=9,\n",
        "                    ha=\"center\", va=\"top\", fontweight=\"bold\")\n",
        "        ax.set_xlim(years[0], years[-1])\n",
        "        ax.set_ylim(np.nanmin(mean_values)*0.95, np.nanmax(mean_values)*1.15)\n",
        "        ax.set_title(f\"{label} in WRB {scenario} ({unit})\", fontsize=12, fontweight=\"bold\")\n",
        "        ax.set_xlabel(\"Year\")\n",
        "        ax.set_ylabel(unit)\n",
        "        ax.grid(True, linestyle=\"--\", alpha=0.6)\n",
        "        ax.legend(loc=\"upper left\", fontsize=9, frameon=True, facecolor=\"white\", framealpha=0.8)\n",
        "        fig.subplots_adjust(bottom=0.15, top=0.9)\n",
        "\n",
        "    trend_gif = f\"{save_dir}/{var_name}_{scenario}_trend.gif\"\n",
        "    trend_anim = FuncAnimation(fig, update_trend, frames=len(years), interval=300)\n",
        "    trend_anim.save(trend_gif, writer=\"pillow\")\n",
        "    plt.close(fig)\n",
        "\n",
        "    # === Combine GIFs ===\n",
        "    map_frames = Image.open(map_gif)\n",
        "    trend_frames = Image.open(trend_gif)\n",
        "    frames = []\n",
        "    for i in range(map_frames.n_frames):\n",
        "        map_frames.seek(i)\n",
        "        trend_frames.seek(i)\n",
        "        map_img = map_frames.convert(\"RGBA\")\n",
        "        trend_img = trend_frames.convert(\"RGBA\").resize((map_img.width, trend_frames.height))\n",
        "        new_frame = Image.new(\"RGBA\", (map_img.width, map_img.height + trend_img.height), (255, 255, 255, 255))\n",
        "        new_frame.paste(map_img, (0, 0))\n",
        "        new_frame.paste(trend_img, (0, map_img.height))\n",
        "        frames.append(new_frame)\n",
        "\n",
        "    combined_gif = f\"{save_dir}/{var_name}_{scenario}_combined.gif\"\n",
        "    frames[0].save(combined_gif, save_all=True, append_images=frames[1:], loop=0, duration=300)\n",
        "    print(\"✅ Saved:\", combined_gif)\n",
        "\n",
        "# === Define Scenarios and Variables\n",
        "scenarios = [\"ssp245\", \"ssp585\"]\n",
        "variables = {\n",
        "    \"tasmin\": {\"label\": \"Annual Min Temperature\", \"cmap\": \"coolwarm\", \"unit\": \"K\", \"is_sum\": False},\n",
        "    \"tasmax\": {\"label\": \"Annual Max Temperature\", \"cmap\": \"coolwarm\", \"unit\": \"K\", \"is_sum\": False},\n",
        "    \"pr\":     {\"label\": \"Annual Precipitation\",    \"cmap\": \"YlGnBu\",   \"unit\": \"mm/year\", \"is_sum\": True}\n",
        "}\n",
        "\n",
        "# === Prepare Task Arguments (using clipped files)\n",
        "task_args = []\n",
        "for scenario in scenarios:\n",
        "    for var, props in variables.items():\n",
        "        file_path = f\"/content/drive/MyDrive/WRB/clipped_data/20km/wrb_{var}_{scenario}_fut_clipped.nc\"\n",
        "        task_args.append((file_path, var, scenario, props, wrb_shape))\n",
        "\n",
        "# === Run in Parallel\n",
        "def run_visualization(args):\n",
        "    file_path, var_name, scenario, props, shape = args\n",
        "    start = time.time()\n",
        "    print(f\"▶️ Starting: {var_name} | {scenario}\")\n",
        "    visualize_climate_variable(\n",
        "        file_path=file_path,\n",
        "        var_name=var_name,\n",
        "        scenario=scenario,\n",
        "        label=props[\"label\"],\n",
        "        cmap=props[\"cmap\"],\n",
        "        unit=props[\"unit\"],\n",
        "        is_sum=props[\"is_sum\"],\n",
        "        shape=shape\n",
        "    )\n",
        "    end = time.time()\n",
        "    duration = timedelta(seconds=end - start)\n",
        "    print(f\"✅ Done: {var_name} | {scenario} in {duration}\")\n",
        "    return (var_name, scenario, duration)\n",
        "\n",
        "start_all = time.time()\n",
        "results = []\n",
        "with ProcessPoolExecutor(max_workers=3) as executor:\n",
        "    futures = {executor.submit(run_visualization, args): args for args in task_args}\n",
        "    total = len(futures)\n",
        "    completed = 0\n",
        "    for future in as_completed(futures):\n",
        "        result = future.result()\n",
        "        results.append(result)\n",
        "        completed += 1\n",
        "        elapsed = time.time() - start_all\n",
        "        avg_time = elapsed / completed\n",
        "        remaining = avg_time * (total - completed)\n",
        "        print(f\"⏳ {completed}/{total} done | Est. time left: {timedelta(seconds=remaining)}\")\n",
        "# Summary\n",
        "print(\"\\n📋 Task Summary:\")\n",
        "for var, scenario, duration in results:\n",
        "    print(f\"• {var} | {scenario} → {duration}\")\n",
        "print(f\"\\n🏁 Total time: {timedelta(seconds=time.time() - start_all)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uef-ioa50vTz",
        "outputId": "be5f5258-880d-407f-802d-795e70061554"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▶️ Starting: tasmax | ssp245▶️ Starting: tasmin | ssp245▶️ Starting: pr | ssp245\n",
            "\n",
            "\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/wrb_gifs/20kmbuffer/tasmax_ssp245_combined.gif\n",
            "✅ Done: tasmax | ssp245 in 0:02:11.133967\n",
            "▶️ Starting: tasmin | ssp585\n",
            "⏳ 1/6 done | Est. time left: 0:10:55.991185\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/wrb_gifs/20kmbuffer/pr_ssp245_combined.gif\n",
            "✅ Done: pr | ssp245 in 0:02:12.667637\n",
            "▶️ Starting: tasmax | ssp585\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/wrb_gifs/20kmbuffer/tasmin_ssp245_combined.gif\n",
            "✅ Done: tasmin | ssp245 in 0:02:12.715457\n",
            "▶️ Starting: pr | ssp585\n",
            "⏳ 2/6 done | Est. time left: 0:04:25.431499\n",
            "⏳ 3/6 done | Est. time left: 0:02:12.756778\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/wrb_gifs/20kmbuffer/tasmin_ssp585_combined.gif\n",
            "✅ Done: tasmin | ssp585 in 0:02:09.385759\n",
            "⏳ 4/6 done | Est. time left: 0:02:10.306733\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/wrb_gifs/20kmbuffer/tasmax_ssp585_combined.gif\n",
            "✅ Done: tasmax | ssp585 in 0:02:08.866131\n",
            "✅ Saved: /content/drive/MyDrive/climate_outputs/wrb_gifs/20kmbuffer/pr_ssp585_combined.gif\n",
            "✅ Done: pr | ssp585 in 0:02:08.881442\n",
            "⏳ 5/6 done | Est. time left: 0:00:52.319009\n",
            "⏳ 6/6 done | Est. time left: 0:00:00\n",
            "\n",
            "📋 Task Summary:\n",
            "• tasmax | ssp245 → 0:02:11.133967\n",
            "• pr | ssp245 → 0:02:12.667637\n",
            "• tasmin | ssp245 → 0:02:12.715457\n",
            "• tasmin | ssp585 → 0:02:09.385759\n",
            "• tasmax | ssp585 → 0:02:08.866131\n",
            "• pr | ssp585 → 0:02:08.881442\n",
            "\n",
            "🏁 Total time: 0:04:21.702317\n"
          ]
        }
      ]
    }
  ]
}